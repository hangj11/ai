{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e015573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 32)   896         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 32)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 32)   9248        ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 32)   9248        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 32)   0           ['batch_normalization[0][0]',    \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 32)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 32)   9248        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 32)   9248        ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 32)   0           ['activation[0][0]',             \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 32)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 4, 4, 32)    0           ['activation_1[0][0]']           \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          262656      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           5130        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 306,314\n",
      "Trainable params: 305,994\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = cifar10.load_data()\n",
    "print('x_train shape:', train_X.shape)\n",
    "print(train_X.shape[0], 'train samples')\n",
    "\n",
    "input_shape = train_X.shape[1:]\n",
    "\n",
    "train_X = train_X.astype('float32') / 255\n",
    "test_X = test_X.astype('float32') / 255\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')\n",
    "x = conv(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding='same', activation='relu',\n",
    "              kernel_regularizer=l2(1e-4))\n",
    "y = conv(x)\n",
    "y = BatchNormalization()(y)\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding='same',\n",
    "              kernel_regularizer=l2(1e-4))\n",
    "y = conv(y)\n",
    "y = BatchNormalization()(y)\n",
    "\n",
    "x = keras.layers.add([x, y])\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding='same',\n",
    "              activation='relu',\n",
    "              kernel_regularizer=l2(1e-4))\n",
    "y = conv(x)\n",
    "y = BatchNormalization()(y)\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding='same',\n",
    "              kernel_regularizer=l2(1e-4))\n",
    "y = conv(y)\n",
    "y = BatchNormalization()(y)\n",
    "\n",
    "x = keras.layers.add([x, y])\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=8)(x)\n",
    "y = Flatten()(x)\n",
    "\n",
    "y = Dense(512, activation='relu')(y)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(y)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a11e8ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4156 - accuracy: 0.4952\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.20830, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-001-0.2083.h5\n",
      "250/250 [==============================] - 8s 23ms/step - loss: 1.4156 - accuracy: 0.4952 - val_loss: 2.9573 - val_accuracy: 0.2083\n",
      "Epoch 2/100\n",
      "  4/250 [..............................] - ETA: 5s - loss: 1.0880 - accuracy: 0.6175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JK\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.9982 - accuracy: 0.6481\n",
      "Epoch 00002: val_accuracy improved from 0.20830 to 0.50420, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-002-0.5042.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.9982 - accuracy: 0.6481 - val_loss: 1.4692 - val_accuracy: 0.5042\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8420 - accuracy: 0.7085\n",
      "Epoch 00003: val_accuracy improved from 0.50420 to 0.70980, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-003-0.7098.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.8420 - accuracy: 0.7085 - val_loss: 0.8480 - val_accuracy: 0.7098\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7443 - accuracy: 0.7427\n",
      "Epoch 00004: val_accuracy did not improve from 0.70980\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.7443 - accuracy: 0.7427 - val_loss: 0.9332 - val_accuracy: 0.6807\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6761 - accuracy: 0.7680\n",
      "Epoch 00005: val_accuracy did not improve from 0.70980\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.6761 - accuracy: 0.7680 - val_loss: 0.8899 - val_accuracy: 0.6958\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6183 - accuracy: 0.7878\n",
      "Epoch 00006: val_accuracy improved from 0.70980 to 0.73610, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-006-0.7361.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.6183 - accuracy: 0.7878 - val_loss: 0.7742 - val_accuracy: 0.7361\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.8080\n",
      "Epoch 00007: val_accuracy improved from 0.73610 to 0.74820, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-007-0.7482.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.5639 - accuracy: 0.8080 - val_loss: 0.7492 - val_accuracy: 0.7482\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.8222\n",
      "Epoch 00008: val_accuracy did not improve from 0.74820\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.5223 - accuracy: 0.8222 - val_loss: 0.9829 - val_accuracy: 0.6846\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.8365\n",
      "Epoch 00009: val_accuracy did not improve from 0.74820\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.4845 - accuracy: 0.8365 - val_loss: 0.8506 - val_accuracy: 0.7351\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4453 - accuracy: 0.8497\n",
      "Epoch 00010: val_accuracy improved from 0.74820 to 0.75180, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-010-0.7518.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.4453 - accuracy: 0.8497 - val_loss: 0.7701 - val_accuracy: 0.7518\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.8602\n",
      "Epoch 00011: val_accuracy improved from 0.75180 to 0.76800, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-011-0.7680.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.4163 - accuracy: 0.8602 - val_loss: 0.7255 - val_accuracy: 0.7680\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8724\n",
      "Epoch 00012: val_accuracy improved from 0.76800 to 0.77280, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-012-0.7728.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.3787 - accuracy: 0.8724 - val_loss: 0.7105 - val_accuracy: 0.7728\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8850\n",
      "Epoch 00013: val_accuracy improved from 0.77280 to 0.78470, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-013-0.7847.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.3464 - accuracy: 0.8850 - val_loss: 0.6831 - val_accuracy: 0.7847\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8954\n",
      "Epoch 00014: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.3177 - accuracy: 0.8954 - val_loss: 0.7597 - val_accuracy: 0.7637\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2948 - accuracy: 0.9034\n",
      "Epoch 00015: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.2948 - accuracy: 0.9034 - val_loss: 0.7219 - val_accuracy: 0.7770\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2693 - accuracy: 0.9133\n",
      "Epoch 00016: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.2693 - accuracy: 0.9133 - val_loss: 0.7440 - val_accuracy: 0.7807\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.9222\n",
      "Epoch 00017: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.2469 - accuracy: 0.9222 - val_loss: 0.8757 - val_accuracy: 0.7518\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.9298\n",
      "Epoch 00018: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.2242 - accuracy: 0.9298 - val_loss: 0.8254 - val_accuracy: 0.7728\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 0.9393\n",
      "Epoch 00019: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.2010 - accuracy: 0.9393 - val_loss: 0.8331 - val_accuracy: 0.7716\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9428\n",
      "Epoch 00020: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.1881 - accuracy: 0.9428 - val_loss: 0.8191 - val_accuracy: 0.7845\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9502\n",
      "Epoch 00021: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.1663 - accuracy: 0.9502 - val_loss: 0.8232 - val_accuracy: 0.7842\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9590\n",
      "Epoch 00022: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.1452 - accuracy: 0.9590 - val_loss: 0.8896 - val_accuracy: 0.7727\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.9606\n",
      "Epoch 00023: val_accuracy did not improve from 0.78470\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.1357 - accuracy: 0.9606 - val_loss: 0.8915 - val_accuracy: 0.7772\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9626\n",
      "Epoch 00024: val_accuracy improved from 0.78470 to 0.78880, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-024-0.7888.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.1327 - accuracy: 0.9626 - val_loss: 0.8832 - val_accuracy: 0.7888\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9642 ETA: 1s -\n",
      "Epoch 00025: val_accuracy did not improve from 0.78880\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.1268 - accuracy: 0.9642 - val_loss: 1.0174 - val_accuracy: 0.7624\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9771\n",
      "Epoch 00026: val_accuracy did not improve from 0.78880\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0971 - accuracy: 0.9771 - val_loss: 0.9298 - val_accuracy: 0.7859\n",
      "Epoch 27/100\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9765\n",
      "Epoch 00027: val_accuracy did not improve from 0.78880\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0979 - accuracy: 0.9764 - val_loss: 0.9797 - val_accuracy: 0.7817\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9756\n",
      "Epoch 00028: val_accuracy did not improve from 0.78880\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0972 - accuracy: 0.9756 - val_loss: 1.1075 - val_accuracy: 0.7682\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.9782\n",
      "Epoch 00029: val_accuracy did not improve from 0.78880\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0904 - accuracy: 0.9782 - val_loss: 1.0124 - val_accuracy: 0.7855\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 0.9834\n",
      "Epoch 00030: val_accuracy improved from 0.78880 to 0.79070, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-030-0.7907.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0781 - accuracy: 0.9834 - val_loss: 1.0135 - val_accuracy: 0.7907\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9811\n",
      "Epoch 00031: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0825 - accuracy: 0.9811 - val_loss: 1.1365 - val_accuracy: 0.7720\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9795 ETA: 0s - l\n",
      "Epoch 00032: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0853 - accuracy: 0.9795 - val_loss: 1.1289 - val_accuracy: 0.7765\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9842\n",
      "Epoch 00033: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0733 - accuracy: 0.9842 - val_loss: 1.1071 - val_accuracy: 0.7813\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.9829\n",
      "Epoch 00034: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0763 - accuracy: 0.9829 - val_loss: 1.1729 - val_accuracy: 0.7801\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0722 - accuracy: 0.9841\n",
      "Epoch 00035: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0722 - accuracy: 0.9841 - val_loss: 1.2065 - val_accuracy: 0.7703\n",
      "Epoch 36/100\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9809\n",
      "Epoch 00036: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0805 - accuracy: 0.9808 - val_loss: 1.3574 - val_accuracy: 0.7561\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9838\n",
      "Epoch 00037: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0713 - accuracy: 0.9838 - val_loss: 1.2214 - val_accuracy: 0.7805\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9828\n",
      "Epoch 00038: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0759 - accuracy: 0.9828 - val_loss: 1.1886 - val_accuracy: 0.7860\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.9807\n",
      "Epoch 00039: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0798 - accuracy: 0.9807 - val_loss: 1.2347 - val_accuracy: 0.7757\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.9876\n",
      "Epoch 00040: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0618 - accuracy: 0.9876 - val_loss: 1.2314 - val_accuracy: 0.7862\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9830\n",
      "Epoch 00041: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0740 - accuracy: 0.9830 - val_loss: 1.3748 - val_accuracy: 0.7661\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9874\n",
      "Epoch 00042: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0621 - accuracy: 0.9874 - val_loss: 1.3188 - val_accuracy: 0.7792\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0610 - accuracy: 0.9878\n",
      "Epoch 00043: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0610 - accuracy: 0.9878 - val_loss: 1.3755 - val_accuracy: 0.7712\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9863\n",
      "Epoch 00044: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0654 - accuracy: 0.9863 - val_loss: 1.3276 - val_accuracy: 0.7732\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.9815\n",
      "Epoch 00045: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0779 - accuracy: 0.9815 - val_loss: 1.4095 - val_accuracy: 0.7742\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9899\n",
      "Epoch 00046: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0552 - accuracy: 0.9899 - val_loss: 1.2905 - val_accuracy: 0.7885\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9906 ETA: 0s - loss: 0.0537 - accu\n",
      "Epoch 00047: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0537 - accuracy: 0.9906 - val_loss: 1.3559 - val_accuracy: 0.7782\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9900\n",
      "Epoch 00048: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0546 - accuracy: 0.9900 - val_loss: 1.5377 - val_accuracy: 0.7701\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9824\n",
      "Epoch 00049: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0753 - accuracy: 0.9824 - val_loss: 1.3989 - val_accuracy: 0.7710\n",
      "Epoch 50/100\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9880\n",
      "Epoch 00050: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0598 - accuracy: 0.9880 - val_loss: 1.4251 - val_accuracy: 0.7717\n",
      "Epoch 51/100\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9880\n",
      "Epoch 00051: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0604 - accuracy: 0.9880 - val_loss: 1.3581 - val_accuracy: 0.7852\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9887\n",
      "Epoch 00052: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0583 - accuracy: 0.9887 - val_loss: 1.7858 - val_accuracy: 0.7348\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9867\n",
      "Epoch 00053: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0646 - accuracy: 0.9867 - val_loss: 1.4999 - val_accuracy: 0.7729\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.9894\n",
      "Epoch 00054: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0573 - accuracy: 0.9894 - val_loss: 1.3791 - val_accuracy: 0.7843\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9925\n",
      "Epoch 00055: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0480 - accuracy: 0.9925 - val_loss: 1.4425 - val_accuracy: 0.7861\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9935\n",
      "Epoch 00056: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0469 - accuracy: 0.9935 - val_loss: 1.5421 - val_accuracy: 0.7766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.9885\n",
      "Epoch 00057: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0580 - accuracy: 0.9885 - val_loss: 1.6402 - val_accuracy: 0.7709\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 0.9853\n",
      "Epoch 00058: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.0669 - accuracy: 0.9853 - val_loss: 1.4673 - val_accuracy: 0.7684\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9846\n",
      "Epoch 00059: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.0694 - accuracy: 0.9846 - val_loss: 1.6563 - val_accuracy: 0.7626\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9916\n",
      "Epoch 00060: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0506 - accuracy: 0.9916 - val_loss: 1.4951 - val_accuracy: 0.7809\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9899\n",
      "Epoch 00061: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0560 - accuracy: 0.9899 - val_loss: 1.6396 - val_accuracy: 0.7683\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9904\n",
      "Epoch 00062: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.0531 - accuracy: 0.9904 - val_loss: 1.4838 - val_accuracy: 0.7864\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.9908\n",
      "Epoch 00063: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0523 - accuracy: 0.9908 - val_loss: 1.5985 - val_accuracy: 0.7736\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9895\n",
      "Epoch 00064: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0546 - accuracy: 0.9895 - val_loss: 1.4162 - val_accuracy: 0.7841\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9929\n",
      "Epoch 00065: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.0469 - accuracy: 0.9929 - val_loss: 1.4532 - val_accuracy: 0.7822\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9861\n",
      "Epoch 00066: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.0667 - accuracy: 0.9861 - val_loss: 1.4913 - val_accuracy: 0.7866\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9923\n",
      "Epoch 00067: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.0496 - accuracy: 0.9923 - val_loss: 1.4769 - val_accuracy: 0.7839\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9954\n",
      "Epoch 00068: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0403 - accuracy: 0.9954 - val_loss: 1.4988 - val_accuracy: 0.7894\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9895\n",
      "Epoch 00069: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0553 - accuracy: 0.9895 - val_loss: 1.5615 - val_accuracy: 0.7775\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9870\n",
      "Epoch 00070: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0637 - accuracy: 0.9870 - val_loss: 1.6206 - val_accuracy: 0.7692\n",
      "Epoch 71/100\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9901\n",
      "Epoch 00071: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.0542 - accuracy: 0.9901 - val_loss: 1.5453 - val_accuracy: 0.7838\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9911\n",
      "Epoch 00072: val_accuracy did not improve from 0.79070\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0515 - accuracy: 0.9911 - val_loss: 1.5691 - val_accuracy: 0.7791\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9948\n",
      "Epoch 00073: val_accuracy improved from 0.79070 to 0.79240, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-073-0.7924.h5\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.0414 - accuracy: 0.9948 - val_loss: 1.4423 - val_accuracy: 0.7924\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9955\n",
      "Epoch 00074: val_accuracy did not improve from 0.79240\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.0386 - accuracy: 0.9955 - val_loss: 1.7459 - val_accuracy: 0.7816\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9861\n",
      "Epoch 00075: val_accuracy did not improve from 0.79240\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.0674 - accuracy: 0.9861 - val_loss: 1.6619 - val_accuracy: 0.7676\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9852\n",
      "Epoch 00076: val_accuracy did not improve from 0.79240\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0689 - accuracy: 0.9852 - val_loss: 1.6528 - val_accuracy: 0.7705\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.9901\n",
      "Epoch 00077: val_accuracy did not improve from 0.79240\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0536 - accuracy: 0.9901 - val_loss: 1.5579 - val_accuracy: 0.7875\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9957\n",
      "Epoch 00078: val_accuracy did not improve from 0.79240\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0389 - accuracy: 0.9957 - val_loss: 1.5453 - val_accuracy: 0.7865\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9986\n",
      "Epoch 00079: val_accuracy did not improve from 0.79240\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0306 - accuracy: 0.9986 - val_loss: 1.5308 - val_accuracy: 0.7914\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9997\n",
      "Epoch 00080: val_accuracy improved from 0.79240 to 0.80130, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-080-0.8013.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0262 - accuracy: 0.9997 - val_loss: 1.4469 - val_accuracy: 0.8013\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000 ETA: 0s - loss: 0.0240 - ac\n",
      "Epoch 00081: val_accuracy improved from 0.80130 to 0.80490, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-081-0.8049.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.4442 - val_accuracy: 0.8049\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 00082: val_accuracy improved from 0.80490 to 0.80700, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-082-0.8070.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.4339 - val_accuracy: 0.8070\n",
      "Epoch 83/100\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 00083: val_accuracy did not improve from 0.80700\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.4400 - val_accuracy: 0.8066\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 00084: val_accuracy did not improve from 0.80700\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.4484 - val_accuracy: 0.8067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 00085: val_accuracy improved from 0.80700 to 0.80750, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-085-0.8075.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.4494 - val_accuracy: 0.8075\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 00086: val_accuracy improved from 0.80750 to 0.80780, saving model to C:\\Users\\JK\\딥러닝 소스코드\\saved_models\\cifar10_model-086-0.8078.h5\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.4534 - val_accuracy: 0.8078\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 00087: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.4523 - val_accuracy: 0.8069\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 00088: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.4526 - val_accuracy: 0.8072\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9456\n",
      "Epoch 00089: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.2182 - accuracy: 0.9456 - val_loss: 2.5719 - val_accuracy: 0.6276\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.9473\n",
      "Epoch 00090: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.1735 - accuracy: 0.9473 - val_loss: 1.6718 - val_accuracy: 0.7396\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9898\n",
      "Epoch 00091: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0496 - accuracy: 0.9898 - val_loss: 1.3200 - val_accuracy: 0.7863\n",
      "Epoch 92/100\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9975\n",
      "Epoch 00092: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0292 - accuracy: 0.9975 - val_loss: 1.3276 - val_accuracy: 0.7933\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9995\n",
      "Epoch 00093: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0226 - accuracy: 0.9995 - val_loss: 1.3133 - val_accuracy: 0.8009\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9999\n",
      "Epoch 00094: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0198 - accuracy: 0.9999 - val_loss: 1.3119 - val_accuracy: 0.8025\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 00095: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.3211 - val_accuracy: 0.8029\n",
      "Epoch 96/100\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 00096: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.3318 - val_accuracy: 0.8058\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 00097: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.3422 - val_accuracy: 0.8050\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 00098: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.3547 - val_accuracy: 0.8037\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 00099: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3618 - val_accuracy: 0.8046\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 00100: val_accuracy did not improve from 0.80780\n",
      "250/250 [==============================] - 5s 22ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3718 - val_accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_model-{epoch:03d}-{val_accuracy:.4f}.h5'\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 90:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 60:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 40:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "my_callbacks = [checkpoint, lr_scheduler]\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_X, train_y, validation_data=(test_X, test_y),\n",
    "                    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277cf670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 1.3718 - accuracy: 0.8060\n",
      "Test loss: 1.371800422668457\n",
      "Test accuracy: 0.8059999942779541\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(test_X, test_y, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6dbb55d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e01e6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
